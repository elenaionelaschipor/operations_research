{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons License\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br /><span xmlns:dct=\"http://purl.org/dc/terms/\" property=\"dct:title\"><b>Linear Binary Classification by Linear Programming</b></span> by <a xmlns:cc=\"http://creativecommons.org/ns#\" href=\"http://mate.unipv.it/gualandi\" property=\"cc:attributionName\" rel=\"cc:attributionURL\">Stefano Gualandi</a> is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>.<br />Based on a work at <a xmlns:dct=\"http://purl.org/dc/terms/\" href=\"https://github.com/mathcoding/opt4ds\" rel=\"dct:source\">https://github.com/mathcoding/opt4ds</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Run the following script whenever running this script on a Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import sys\n",
    "import os.path\n",
    "\n",
    "if not shutil.which(\"pyomo\"):\n",
    "    !pip install -q pyomo\n",
    "    assert(shutil.which(\"pyomo\"))\n",
    "\n",
    "if not (shutil.which(\"glpk\") or os.path.isfile(\"glpk\")):\n",
    "    if \"google.colab\" in sys.modules:\n",
    "        !apt-get install -y -qq glpk-utils\n",
    "    else:\n",
    "        try:\n",
    "            !conda install -c conda-forge glpk \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Linear Classification by Integer Linear Programming\n",
    "In this lab session, you have to experiment with **(Integer) Linear Programming** to train a **binary linear classifier** for solving three different problems:\n",
    "\n",
    "1. The classification two classes of random points drawn from two different 2D Gaussian distributions.\n",
    "2. The classification of euro banknotes as *regular* or *fake*, given 4 attributes of banknote images:\n",
    "    * Variance of Wavelet Transformed image (continuous)\n",
    "    * Skewness of Wavelet Transformed image (continuous)\n",
    "    * Curtosis of Wavelet Transformed image (continuous)\n",
    "    * Entropy of image (continuous)\n",
    "3. The classification of breast cancer as either malignant (M) or benign (B), given 30 attributes referring to 10 features described below.\n",
    "\n",
    "Your model will be evaluated in terms of overall accuracy, given as the percentage of object classified correctly as either positive or negative.\n",
    "\n",
    "For the banknote and breast cancer classification problems, you have only a subset of the whole dataset. The missing data will be used to nominate the best classifier proposed by the different student groups.\n",
    "\n",
    "To design your classifier, you can only use **(Integer) Linear Programming**. If you will try after the lecture other approaches studied in other courses (e.g., SVM, decision tress, or Neural Networks), I will be very curious the hear about.\n",
    "\n",
    "**REMARK:** If working on your personal computer, you might want to install [Gurobi with an academic license](https://www.gurobi.com/academia/academic-program-and-licenses/). Gurobi is a commercial solver that is extremely fast in solving large ILP instances, much more faster than the free GLPK solver."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Gaussian samples in 2D\n",
    "The first dataset is generated randomly with the following code, which generates a list of $3n$ points in the plane. The first $2n$ points have both coordinates with mean equal to 2.0 and standard deviations $d$ (=0.5 by default), and they belong to the first class; the remaining $n$ points have coordinates with mean equal to 4.0 and standard deviations $d$, and they belong to the second class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def Gaussian(n, mu, sigma):\n",
    "    return np.random.normal(mu, sigma, (n, 2))\n",
    "\n",
    "def RandomData(n, d=0.5):\n",
    "    # To experiment with different random dataset, comment the following line\n",
    "    np.random.seed(17)\n",
    "    \n",
    "    # Generate points\n",
    "    As = Gaussian(2*n, 2, d)\n",
    "    Bs = Gaussian(n, 4, d)       \n",
    "    Xs = []\n",
    "    Ys = []    \n",
    "    for a in As:\n",
    "        Xs.append(a)\n",
    "        Ys.append(0) # First class\n",
    "    for a in Bs:\n",
    "        Xs.append(a)\n",
    "        Ys.append(1) # Second class\n",
    "        \n",
    "    return Xs, Ys\n",
    "\n",
    "Xs, Ys = RandomData(50, 0.25)\n",
    "\n",
    "print(Xs[0], Ys[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, you have generated $m$ points $x_i$ with labels $y_i$, such that the points with $y_i=0$ belongs to the first class, and the point $y_i=1$ belongs to the second class.\n",
    "\n",
    "You have to find a Linear Classifier in 2D, that is, you have to find the hyperplane defined by the vector $(a_0, a_1, a_2)$, such that:\n",
    "\n",
    "$$\n",
    "a_0 x_{i0} + a_1 x_{i1} + a_2 \\geq 0 \\quad \\text{if $x_i$ belong to the first class } (y_i=0)\\\\\n",
    "a_0 x_{i0} + a_1 x_{i1} + a_2 < 0 \\quad \\text{if $x_i$ belong to the second class } (y_i=1)\\\\\n",
    "$$\n",
    "\n",
    "For instance, the (very bad!) linear classifier specified by $(a_0, a_1, a_2)=(1,-1,0.5)$, classifies each point of the dataset as shown in the following graphical representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def PlotSolution(Xs, Ys, A):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    # Left plot\n",
    "    ax1.scatter([x[0] for x in Xs], [x[1] for x in Xs], \n",
    "                color=['green' if y == 1 else 'blue' for y in Ys],\n",
    "                alpha=0.35)\n",
    "    # Right plot\n",
    "    ax2.scatter([x[0] for x in Xs], [x[1] for x in Xs], \n",
    "                color=['green' if y == 1 else 'blue' for y in Ys],\n",
    "                alpha=0.35)\n",
    "    \n",
    "    xmin = min(x[0] for x in Xs)\n",
    "    xmax = max(x[1] for x in Xs)\n",
    "    x = np.linspace(xmin, xmax, 10)\n",
    "    \n",
    "    # Draw the classifier line (over the plot domain)\n",
    "    y = -A[0]/A[1]*x + A[2]/A[1]\n",
    "    \n",
    "    ax2.plot(x, y, color='red')\n",
    "    \n",
    "    # Miss-classifications\n",
    "    Vs = []\n",
    "    for i,x in enumerate(Xs):\n",
    "        if A[0]*x[0] + A[1]*x[1] < A[2] and Ys[i] == 0:\n",
    "            Vs.append(x)                        \n",
    "        else:\n",
    "            if A[0]*x[0] + A[1]*x[1] > A[2] and Ys[i] == 1:\n",
    "                Vs.append(x)\n",
    "    \n",
    "    ax2.scatter([x[0] for x in Vs], [x[1] for x in Vs], color='red', alpha=0.5, marker='x')\n",
    "    \n",
    "    # Final plot\n",
    "    ax1.axis([xmin-0.5, xmax+0.5, 1, 5.5])\n",
    "    ax2.axis([xmin-0.5, xmax+0.5, 1, 5.5])\n",
    "    ax1.axis('equal')\n",
    "    ax2.axis('equal')\n",
    "    # plt.savefig('lin_classifier.pdf') \n",
    "    plt.show() \n",
    "    \n",
    "# HOW-TO PLOT\n",
    "PlotSolution(Xs, Ys, [-1,-1,-6])  # <<<<============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the classifier in terms of *accuracy* and/or by using the *confusion matrix*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Accuracy(A, Bx, Bl):\n",
    "    # Count overall miss-classifications\n",
    "    v = 0\n",
    "    for xs, y in zip(Bx, Bl):\n",
    "        ax = sum(x*a for x,a in zip(xs, A[:-1]))\n",
    "        if ax <= A[-1] and y == 0:\n",
    "            v += 1\n",
    "        if ax > A[-1] and y == 1:\n",
    "            v += 1    \n",
    "    return round((len(Bx)-v)/len(Bx)*100, 3), len(Bx)-v, len(Bx)\n",
    "\n",
    "def Confusion(A, Bx, Bl):\n",
    "    # Compute in order:\n",
    "    # True Positive, False Positive, True Negative, False Negative\n",
    "    tp, fp, tn, fn = 0, 0, 0, 0    \n",
    "    for xs, y in zip(Bx, Bl):\n",
    "        ax = sum(x*a for x,a in zip(xs, A[:-1]))\n",
    "        if ax >= A[-1] and y == 0:\n",
    "            tn += 1\n",
    "        if ax < A[-1] and y == 1:\n",
    "            tp += 1\n",
    "            \n",
    "        if ax < A[-1] and y == 0:\n",
    "            fn += 1\n",
    "        if ax >= A[-1] and y == 1:\n",
    "            fp += 1    \n",
    "    return tp, fp, tn, fn\n",
    "\n",
    "# HOW-TO EVALUATE  # <<<<============\n",
    "print(\"Accuracy:\", Accuracy([1,-1,0.5], Xs, Ys))\n",
    "print(\"Confusion Matrix:\", Confusion([1,-1,0.5], Xs, Ys))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This classifier is indeed very poor: flipping a coin could give better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE 1:** Design your best possible Linear Classifier using Integer Linear Programming and Pyomo. Use the visual representation in 2D to get intuition on your classifier. Try to change the initial random distributions (mean and deviation).\n",
    "\n",
    "Implement your solution in the following function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyomo.environ import ConcreteModel, Var, Objective, Constraint, SolverFactory\n",
    "from pyomo.environ import Binary, RangeSet, NonNegativeReals\n",
    "\n",
    "def LinearClassifier(Xs, Ys):\n",
    "    # TO COMPLETE WITH YOUR MODEL\n",
    "    return [1, -1, 0.5]\n",
    "\n",
    "\n",
    "# HOW-TO TEST YOUR SOLUTION\n",
    "A = LinearClassifier(Xs,Ys)  # <<<<============\n",
    "\n",
    "print(\"Accuracy:\", Accuracy(A, Xs, Ys))\n",
    "print(\"Confusion Matrix:\", Confusion(A, Xs, Ys))\n",
    "PlotSolution(Xs, Ys, [1,-1,0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Banknote fake classification\n",
    "In this second exercise, you have to design a Linear Classifier to distinguish between original and fake banknotes.\n",
    "\n",
    "Each single banknote is first digitalized, and second, 4 features of each image are reported in the dataset. The 4 features that you can use are:\n",
    "\n",
    "* Variance of Wavelet Transformed image (continuous)\n",
    "* Skewness of Wavelet Transformed image (continuous)\n",
    "* Curtosis of Wavelet Transformed image (continuous)\n",
    "* Entropy of image (continuous)\n",
    "\n",
    "Your are given a subset of 992 banknotes that you can use to train your model.\n",
    "\n",
    "**GROUP CHALLENGE 1:** Design your best Linear Classifier which will achieve the best **accuracy** on a subset of 380 banknotes that you cannot have access to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DATA:** The data about the banknotes is given via a csv file, with a row for each banknote. The first 4 fields of each row gives the features of the banknote, the last field, while gives a binary label: 0 or 1. You can parse the data with the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command to import the dataset\n",
    "!wget http://www-dimat.unipv.it/gualandi/opt4ds/banknote_train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the training set\n",
    "def ParseData(filename):\n",
    "    fh = open(filename, 'r', encoding=\"utf-8\")\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    for line in fh:\n",
    "        row = line.replace('\\n','').split(',')        \n",
    "        Xs.append( list(map(float, row[:-1])) )\n",
    "        Ys.append( int(row[-1]) )\n",
    "    return Xs, Ys  \n",
    "\n",
    "# HOW-TO PARSE\n",
    "Xs, Ys = ParseData('banknote_train.csv')\n",
    "for i in range(5):\n",
    "    print(Xs[i], Ys[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** You may want to split your data into training and test subsets, in order to verify how your model generalize to *unseen* data (but you are not forced to). In the later case, you can use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitTrainTestSet(Xs, Ys, t=0.3):\n",
    "    Xtrain, Ytrain = [], []  # Train sets\n",
    "    Xtest,  Ytest = [], []  # Test sets\n",
    "    \n",
    "    np.random.seed(13)\n",
    "    \n",
    "    for x, y in zip(Xs, Ys):\n",
    "        if np.random.uniform(0, 1) > t:\n",
    "            Xtrain.append(x)\n",
    "            Ytrain.append(y)\n",
    "        else:\n",
    "            Xtest.append(x)\n",
    "            Ytest.append(y)\n",
    "            \n",
    "    return Xtrain, Ytrain, Xtest, Ytest\n",
    "\n",
    "# HOW-TO USE A DATA SPLITTING\n",
    "Xtrain, Ytrain, Xtest, Ytest = SplitTrainTestSet(Xs, Ys)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearClassifierBank(Xs, Ys):\n",
    "    # TO COMPLETE WITH YOUR DATA\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Breast Cancer Classification\n",
    "In this third exercise, you have to design a Linear Classifier to distinguish between malignant and benign breast cancer tumors, using a set of 30 features precomputed from digitized images of a fine needle aspirate (FNA) of a breast mass.\n",
    "\n",
    "Each single breast mass is first analyzed, and then, the 30 features of each image are reported in the csv file `breast_cancer_train.csv`.\n",
    "\n",
    "Attribute Information, in order by columns as appearing in the CSV file:\n",
    "\n",
    "1. ID number\n",
    "2. Diagnosis (M = malignant, B = benign)\n",
    "3. radius (mean of distances from center to points on the perimeter)\n",
    "4. texture (standard deviation of gray-scale values)\n",
    "5. perimeter\n",
    "6. area\n",
    "7. smoothness (local variation in radius lengths)\n",
    "8. compactness (perimeter^2 / area - 1.0)\n",
    "9. concavity (severity of concave portions of the contour)\n",
    "10. concave points (number of concave portions of the contour)\n",
    "11. symmetry\n",
    "12. fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "For the features from column 3 to 12, the mean is reported with 4 significant digits.\n",
    "The following 10 columns (from 13 to 22) report the standard error of the corresponding feature.\n",
    "The remaining 10 columns (from 23 to 32) report the largest number (worst) of the corresponding feature.\n",
    "\n",
    "For instance, column 3 is Mean Radius, column 13 is Radius SE, and column 23 is Worst Radius.\n",
    "\n",
    "All feature values are recoded with four significant digits.\n",
    "\n",
    "Follow the following steps to import the dataset and then work on your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command to import the dataset\n",
    "!wget http://www-dimat.unipv.it/gualandi/opt4ds/breast_cancer_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse the data, you can use the following basic parser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ParseCancer(filename):\n",
    "    fh = open(filename, 'r', encoding=\"utf-8\")\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    for line in fh:\n",
    "        row = line.replace('\\n','').split(',')        \n",
    "        Xs.append( list(map(float, row[2:])) )\n",
    "        Ys.append( int(row[1] == 'M') )\n",
    "    return Xs, Ys    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can work out your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LinearClassifierBreastCancer(Xs, Ys):\n",
    "    # TO COMPLETE WITH YOUR DATA\n",
    "    return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GROUP CHALLENGE 2:** Design your best Linear Classifier which will achieve the best **accuracy** on a subset of samples that you do not have access to. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Submission and Evaluation\n",
    "Each group (with 1 or 2 students per group) must submit a solution by email before Thursday, 23rd, at midnight.\n",
    "\n",
    "All the submitted classifier will be evaluated during the lecture on Friday, 24th, by using an **unseen** validation dataset.\n",
    "\n",
    "The best group on the unseen dataset will get two extra \"bonus\" points to the final oral exam. All the group submitting a working solution will get an extre point to the final oral exam.\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
